{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Credit OCR System Process"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook demonstrates a complete OCR pipeline for processing credit request documents.\n",
    "It uses Azure Form Recognizer for OCR, Ollama for LLM-based field extraction, and \n",
    "provides visualization capabilities for extracted data.\n",
    "\n",
    "Prerequisites:\n",
    "- Docker installed and running\n",
    "- Python 3.8+ with required packages (see requirements.txt/pyproject.toml)\n",
    "- Azure Form Recognizer service configured\n",
    "- Ollama running locally (automatically started via testcontainers)\n",
    "- Sample credit request PDF document in tests/tmp/\n",
    "\n",
    "The pipeline performs:\n",
    "1. Document OCR using Azure Form Recognizer\n",
    "2. Text extraction with bounding boxes and confidence scores\n",
    "3. LLM-based field extraction using Ollama\n",
    "4. Data visualization and validation\n",
    "5. Database storage (optional)\n",
    "\n",
    "Key components:\n",
    "- Azure OCR client for document analysis\n",
    "- Ollama client for LLM processing\n",
    "- Field extractor for structured data extraction\n",
    "- PDF visualizer for result validation\n",
    "- Configuration management for various services"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard library imports\n",
    "import json\n",
    "import logging\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "import uuid\n",
    "from datetime import datetime\n",
    "from pathlib import Path\n",
    "import requests\n",
    "\n",
    "# Third-party imports\n",
    "import pandas as pd\n",
    "\n",
    "# Set up Python path and working directory FIRST\n",
    "project_root = Path.cwd().parent  # Go up one level from notebooks/\n",
    "sys.path.insert(0, str(project_root))\n",
    "os.chdir(project_root)  # Change to project root for config loading\n",
    "\n",
    "# Import backend modules (now that path is set up)\n",
    "from src.config import AppConfig, DocumentProcessingConfig\n",
    "from src.ocr.azure_ocr_client import analyze_single_document_with_azure\n",
    "from src.ocr.postprocess import extract_text_lines_with_bbox_and_confidence\n",
    "from src.visualization.pdf_visualizer import visualize_extracted_fields"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:src.config:Using Ollama URL from config file: http://127.0.0.1:11435\n",
      "Pulling image ollama/ollama:0.5.13\n",
      "INFO:testcontainers.core.container:Pulling image ollama/ollama:0.5.13\n",
      "Container started: a3e4e0ef0838\n",
      "INFO:testcontainers.core.container:Container started: a3e4e0ef0838\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model name: llama3.1:8b\n",
      "URL: http://127.0.0.1:11435\n",
      "Starting Ollama test container...\n",
      "Ollama started on port 11435\n",
      "Test environment started (Ollama, etc.)\n",
      "Loading Ollama model...\n",
      "Waiting for Ollama to be ready... (attempt 1/30)\n",
      "Ollama is ready\n",
      "Model llama3.1:8b is already loaded\n",
      "Ollama setup complete!\n"
     ]
    }
   ],
   "source": [
    "# Import required modules with proper error handling\n",
    "try:\n",
    "    from testcontainers.core.container import DockerContainer\n",
    "except ImportError as import_error:\n",
    "    print(f\"Import error: {import_error}\")\n",
    "    print(\"Please ensure you're running this from the project root directory\")\n",
    "    print(f\"Current working directory: {os.getcwd()}\")\n",
    "    print(f\"Python path: {sys.path}\")\n",
    "    raise\n",
    "\n",
    "# Load configuration with simple string path (now from project root)\n",
    "app_config: AppConfig = AppConfig(\"config\")\n",
    "print(f\"Model name: {app_config.generative_llm.model_name}\")\n",
    "print(f\"URL: {app_config.generative_llm.url}\")\n",
    "\n",
    "# Use current working directory instead of __file__ for notebook compatibility\n",
    "current_working_directory: str = str(Path.cwd())\n",
    "cache_directory: str = \"ollama_cache_generative\"\n",
    "\n",
    "# Start the generative model with ollama using Docker container (fixed port)\n",
    "print(\"Starting Ollama test container...\")\n",
    "ollama_container = DockerContainer(\"ollama/ollama:0.5.13\")\n",
    "ollama_container.with_exposed_ports(11435)\n",
    "ollama_container.with_bind_ports(11434, 11435)  # Fixed port mapping\n",
    "ollama_container.with_volume_mapping(f\"{current_working_directory}/data/{cache_directory}\", \"/root/.ollama\", \"rw\")\n",
    "ollama_container.start()\n",
    "ollama_port: int = 11435  # Use fixed port instead of dynamic\n",
    "os.environ[\"OLLAMA_HOST\"] = \"localhost\"\n",
    "os.environ[\"OLLAMA_PORT\"] = str(ollama_port)\n",
    "\n",
    "print(f\"Ollama started on port {ollama_port}\")\n",
    "print(\"Test environment started (Ollama, etc.)\")\n",
    "\n",
    "# Load the required model\n",
    "print(\"Loading Ollama model...\")\n",
    "model_name: str = app_config.generative_llm.model_name\n",
    "ollama_url: str = f\"http://localhost:{ollama_port}\"\n",
    "\n",
    "# Wait for Ollama to be ready\n",
    "max_retries: int = 30\n",
    "for attempt in range(max_retries):\n",
    "    try:\n",
    "        response = requests.get(f\"{ollama_url}/api/tags\", timeout=5)\n",
    "        if response.status_code == 200:\n",
    "            print(\"Ollama is ready\")\n",
    "            break\n",
    "    except Exception as e:\n",
    "        if attempt < max_retries - 1:\n",
    "            print(f\"Waiting for Ollama to be ready... (attempt {attempt + 1}/{max_retries})\")\n",
    "            time.sleep(2)\n",
    "        else:\n",
    "            print(f\"Ollama failed to become ready: {e}\")\n",
    "            raise\n",
    "\n",
    "# Check if model is already loaded\n",
    "try:\n",
    "    response = requests.get(f\"{ollama_url}/api/tags\")\n",
    "    if response.status_code == 200:\n",
    "        models = response.json().get(\"models\", [])\n",
    "        model_names = [m.get(\"name\") for m in models]\n",
    "        if model_name in model_names:\n",
    "            print(f\"Model {model_name} is already loaded\")\n",
    "        else:\n",
    "            print(f\"Model {model_name} not found, pulling...\")\n",
    "            # Pull the model\n",
    "            pull_response = requests.post(f\"{ollama_url}/api/pull\", json={\"name\": model_name})\n",
    "            if pull_response.status_code == 200:\n",
    "                print(f\"Model {model_name} pulled successfully\")\n",
    "            else:\n",
    "                print(f\"Failed to pull model: {pull_response.text}\")\n",
    "except Exception as e:\n",
    "    print(f\"Error checking/loading model: {e}\")\n",
    "\n",
    "print(\"Ollama setup complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure logging\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "logger = logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Manually define one CreditRequest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CreditRequest defined:\n",
      "   ID: e66bc98e-2333-4217-bff7-b21b94594d91\n",
      "   Customer: Hotel zur Taube\n",
      "   Type: Immobilienfinanzierung\n",
      "   Purpose: Kauf einer Gewerbeimmobilie\n",
      "   Document ID: 81e1a236-7ca1-452b-8ef6-4ade61a71bba\n",
      "   Document Path: tests/tmp/Kreditantrag_HotelZurTaube.pdf\n",
      "   Document Type: Kreditantrag\n",
      "Document found: tests/tmp/Kreditantrag_HotelZurTaube.pdf\n"
     ]
    }
   ],
   "source": [
    "# Manually define one CreditRequest\n",
    "credit_request_id = str(uuid.uuid4())\n",
    "customer_name = \"Hotel zur Taube\" # TODO: Change customer name\n",
    "credit_request_metadata = {\n",
    "    \"id\": credit_request_id,\n",
    "    \"customer_name\": customer_name,\n",
    "    \"request_type\": \"Immobilienfinanzierung\",\n",
    "    \"purpose\": \"Kauf einer Gewerbeimmobilie\",\n",
    "    \"created_at\": datetime.now().isoformat(),\n",
    "    \"status\": \"In Bearbeitung\"\n",
    "}\n",
    "\n",
    "# Define document information\n",
    "document_filename = \"Kreditantrag_HotelZurTaube.pdf\" # TODO: Change document name\n",
    "document_path = Path(\"tests/tmp\") / document_filename  # Now relative to project root\n",
    "document_type = \"Kreditantrag\"\n",
    "document_id = str(uuid.uuid4())\n",
    "\n",
    "print(f\"CreditRequest defined:\")\n",
    "print(f\"   ID: {credit_request_id}\")\n",
    "print(f\"   Customer: {customer_name}\")\n",
    "print(f\"   Type: {credit_request_metadata['request_type']}\")\n",
    "print(f\"   Purpose: {credit_request_metadata['purpose']}\")\n",
    "print(f\"   Document ID: {document_id}\")\n",
    "print(f\"   Document Path: {document_path}\")\n",
    "print(f\"   Document Type: {document_type}\")\n",
    "\n",
    "# Verify document exists\n",
    "if not document_path.exists():\n",
    "    raise FileNotFoundError(f\"Document not found: {document_path}\")\n",
    "print(f\"Document found: {document_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Run OCR with Azure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:src.ocr.azure_ocr_client:Sending document to Azure OCR: tests/tmp/Kreditantrag_HotelZurTaube.pdf\n",
      "INFO:azure.core.pipeline.policies.http_logging_policy:Request URL: 'https://free-f0-instance.cognitiveservices.azure.com/formrecognizer/documentModels/prebuilt-document:analyze?stringIndexType=unicodeCodePoint&api-version=2023-07-31'\n",
      "Request method: 'POST'\n",
      "Request headers:\n",
      "    'Content-Type': 'application/octet-stream'\n",
      "    'Accept': 'application/json'\n",
      "    'x-ms-client-request-id': '467114a6-567c-11f0-ae5c-ed518bc750bc'\n",
      "    'User-Agent': 'azsdk-python-ai-formrecognizer/3.3.3 Python/3.10.16 (macOS-15.1-arm64-arm-64bit)'\n",
      "    'Ocp-Apim-Subscription-Key': 'REDACTED'\n",
      "A body is sent with the request\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running Azure OCR...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:azure.core.pipeline.policies.http_logging_policy:Response status: 202\n",
      "Response headers:\n",
      "    'Content-Length': '0'\n",
      "    'Operation-Location': 'https://free-f0-instance.cognitiveservices.azure.com/formrecognizer/documentModels/prebuilt-document/analyzeResults/f219603d-601f-42da-a715-b5c440b5c0a9?api-version=2023-07-31'\n",
      "    'x-envoy-upstream-service-time': '104'\n",
      "    'apim-request-id': 'f219603d-601f-42da-a715-b5c440b5c0a9'\n",
      "    'Strict-Transport-Security': 'max-age=31536000; includeSubDomains; preload'\n",
      "    'x-content-type-options': 'nosniff'\n",
      "    'x-ms-region': 'East US'\n",
      "    'Date': 'Tue, 01 Jul 2025 13:07:01 GMT'\n",
      "INFO:azure.core.pipeline.policies.http_logging_policy:Request URL: 'https://free-f0-instance.cognitiveservices.azure.com/formrecognizer/documentModels/prebuilt-document/analyzeResults/f219603d-601f-42da-a715-b5c440b5c0a9?api-version=2023-07-31'\n",
      "Request method: 'GET'\n",
      "Request headers:\n",
      "    'x-ms-client-request-id': '467114a6-567c-11f0-ae5c-ed518bc750bc'\n",
      "    'User-Agent': 'azsdk-python-ai-formrecognizer/3.3.3 Python/3.10.16 (macOS-15.1-arm64-arm-64bit)'\n",
      "    'Ocp-Apim-Subscription-Key': 'REDACTED'\n",
      "No body was attached to the request\n",
      "INFO:azure.core.pipeline.policies.http_logging_policy:Response status: 200\n",
      "Response headers:\n",
      "    'Content-Length': '106'\n",
      "    'Content-Type': 'application/json; charset=utf-8'\n",
      "    'retry-after': '5'\n",
      "    'x-envoy-upstream-service-time': '35'\n",
      "    'apim-request-id': '349bbf49-c046-4393-b1b1-c12314a83375'\n",
      "    'Strict-Transport-Security': 'max-age=31536000; includeSubDomains; preload'\n",
      "    'x-content-type-options': 'nosniff'\n",
      "    'x-ms-region': 'East US'\n",
      "    'Date': 'Tue, 01 Jul 2025 13:07:01 GMT'\n",
      "INFO:azure.core.pipeline.policies.http_logging_policy:Request URL: 'https://free-f0-instance.cognitiveservices.azure.com/formrecognizer/documentModels/prebuilt-document/analyzeResults/f219603d-601f-42da-a715-b5c440b5c0a9?api-version=2023-07-31'\n",
      "Request method: 'GET'\n",
      "Request headers:\n",
      "    'x-ms-client-request-id': '467114a6-567c-11f0-ae5c-ed518bc750bc'\n",
      "    'User-Agent': 'azsdk-python-ai-formrecognizer/3.3.3 Python/3.10.16 (macOS-15.1-arm64-arm-64bit)'\n",
      "    'Ocp-Apim-Subscription-Key': 'REDACTED'\n",
      "No body was attached to the request\n",
      "INFO:azure.core.pipeline.policies.http_logging_policy:Response status: 200\n",
      "Response headers:\n",
      "    'Content-Length': '45843'\n",
      "    'Content-Type': 'application/json; charset=utf-8'\n",
      "    'x-envoy-upstream-service-time': '65'\n",
      "    'apim-request-id': '02e48250-6417-4390-97ed-430497a8fb5c'\n",
      "    'Strict-Transport-Security': 'max-age=31536000; includeSubDomains; preload'\n",
      "    'x-content-type-options': 'nosniff'\n",
      "    'x-ms-region': 'East US'\n",
      "    'Date': 'Tue, 01 Jul 2025 13:07:06 GMT'\n",
      "INFO:src.ocr.azure_ocr_client:Result retrieved from Azure OCR for tests/tmp/Kreditantrag_HotelZurTaube.pdf\n",
      "INFO:src.ocr.azure_ocr_client:Number of pages: 1\n",
      "INFO:src.ocr.azure_ocr_client:Word: Kreditantrag, Confidence: 0.995\n",
      "INFO:src.ocr.azure_ocr_client:Word: zur, Confidence: 0.996\n",
      "INFO:src.ocr.azure_ocr_client:Word: Beantragung, Confidence: 0.993\n",
      "INFO:src.ocr.azure_ocr_client:Word: eines, Confidence: 0.995\n",
      "INFO:src.ocr.azure_ocr_client:Word: gewerblichen, Confidence: 0.994\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OCR completed: 164 lines extracted\n"
     ]
    }
   ],
   "source": [
    "print(\"Running Azure OCR...\")\n",
    "azure_ocr_result = analyze_single_document_with_azure(str(document_path))\n",
    "ocr_lines = extract_text_lines_with_bbox_and_confidence(azure_ocr_result)\n",
    "print(f\"OCR completed: {len(ocr_lines)} lines extracted\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OCR post-processing completed: 76 normalized lines\n"
     ]
    }
   ],
   "source": [
    "from src.ocr.postprocess import normalize_ocr_lines\n",
    "normalized_ocr_lines = normalize_ocr_lines(ocr_lines)\n",
    "print(f\"OCR post-processing completed: {len(normalized_ocr_lines)} normalized lines\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_config = DocumentProcessingConfig.from_json(\"config/document_types.conf\")\n",
    "credit_request_config = doc_config.document_types[\"credit_request\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualization_dir = Path(f\"notebooks/docs/{customer_name}\")\n",
    "visualization_dir.mkdir(exist_ok=True)\n",
    "visualization_path = visualization_dir / f\"{document_id}_annotated.png\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:src.visualization.pdf_visualizer:Drew 42 boxes on page 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Visualization generated: notebooks/docs/Hotel zur Taube/81e1a236-7ca1-452b-8ef6-4ade61a71bba_annotated.png\n"
     ]
    }
   ],
   "source": [
    "visualize_extracted_fields(\n",
    "    pdf_path=document_path,\n",
    "    normalized_data=normalized_ocr_lines,\n",
    "    output_path=visualization_path,\n",
    "    doc_config=credit_request_config\n",
    ")\n",
    "print(f\"Visualization generated: {visualization_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting structured fields from OCR data...\n",
      "\n",
      "Extracted fields:\n",
      "   company_name: Hotel zur Taube\n",
      "   legal_form: Personengesellschaft\n",
      "   founding_date: 01.01.2010\n",
      "   business_address: Taubenstraße6, 89264\n",
      "   commercial_register: 3423431242\n",
      "   vat_id: 987654\n",
      "   property_type: Hotel zur Taube\n",
      "   property_name: Hotel zor Taube\n",
      "   property_address: Taubenstraße 6, 89264\n",
      "   purchase_price: 300.000\n",
      "   requested_amount: 220.000\n",
      "   purpose: Renovierung\n",
      "   equity_share: 60.0\n",
      "   construction_year: 2006\n",
      "   total_area: 250gm\n",
      "   loan_amount: 220.000\n",
      "   term: 50 Monate\n",
      "   monthly_payment: 5.000\n",
      "   interest_rate: fest\n",
      "\n",
      "Missing fields: ['website']\n"
     ]
    }
   ],
   "source": [
    "print(\"Extracting structured fields from OCR data...\")\n",
    "\n",
    "from src.llm.field_extractor import extract_fields_with_llm\n",
    "from src.llm.client import OllamaClient\n",
    "import asyncio\n",
    "import nest_asyncio\n",
    "\n",
    "llm_client = OllamaClient(\n",
    "    base_url=app_config.generative_llm.url,\n",
    "    model_name=app_config.generative_llm.model_name\n",
    ")\n",
    "\n",
    "def run_async_in_notebook(coro):\n",
    "    try:\n",
    "        loop = asyncio.get_running_loop()\n",
    "    except RuntimeError:\n",
    "        loop = None\n",
    "\n",
    "    if loop and loop.is_running():\n",
    "        nest_asyncio.apply()\n",
    "        return loop.run_until_complete(coro)\n",
    "    else:\n",
    "        return asyncio.run(coro)\n",
    "\n",
    "try:\n",
    "    extracted_fields_result = run_async_in_notebook(extract_fields_with_llm(\n",
    "        ocr_lines=normalized_ocr_lines,\n",
    "        doc_config=credit_request_config,\n",
    "        llm_client=llm_client,\n",
    "        original_ocr_lines=ocr_lines\n",
    "    ))\n",
    "\n",
    "    extracted_fields = extracted_fields_result.get('extracted_fields', {})\n",
    "    missing_fields = extracted_fields_result.get('missing_fields', [])\n",
    "    validation_results = extracted_fields_result.get('validation_results', {})\n",
    "\n",
    "    # Only keep fields that are actually present and non-empty\n",
    "    normalized_fields = {\n",
    "        field_name: field_data['value'] if isinstance(field_data, dict) and 'value' in field_data else str(field_data)\n",
    "        for field_name, field_data in extracted_fields.items()\n",
    "        if field_data and (isinstance(field_data, dict) and field_data.get('value')) or (isinstance(field_data, str) and field_data.strip())\n",
    "    }\n",
    "\n",
    "    print(\"\\nExtracted fields:\")\n",
    "    for field_name, value in normalized_fields.items():\n",
    "        print(f\"   {field_name}: {value}\")\n",
    "\n",
    "    if missing_fields:\n",
    "        print(f\"\\nMissing fields: {missing_fields}\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"LLM extraction failed: {e}\")\n",
    "    normalized_fields = {}\n",
    "    # Stop and remove the Ollama container\n",
    "    try:\n",
    "        ollama_container.stop()\n",
    "        print(\"Ollama container stopped and removed successfully\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error stopping/removing container: {e}\")\n",
    "        # Stop and remove the Ollama container\n",
    "        try:\n",
    "            ollama_container.stop()\n",
    "            print(\"Ollama container stopped and removed successfully\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error stopping/removing container: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare OCR Data\n",
    "extrahierte_daten_data = []\n",
    "for field_name, field_data in extracted_fields.items():\n",
    "    if field_data and isinstance(field_data, dict) and field_data.get('value'):\n",
    "        field_value = field_data['value']\n",
    "        confidence_score = field_data.get('confidence', 0.5)\n",
    "        bounding_box = field_data.get('bounding_box')\n",
    "        page_number = field_data.get('page')\n",
    "        \n",
    "        # Convert bounding box to JSON string if it exists\n",
    "        position_info = json.dumps(bounding_box) if bounding_box else None\n",
    "        \n",
    "        extrahierte_daten_data.append({\n",
    "            \"Feldname\": field_name,\n",
    "            \"Wert\": field_value,\n",
    "            \"Position im Dokument\": position_info,\n",
    "            \"Konfidenzscore\": confidence_score,\n",
    "            \"FK_Dokument\": document_id\n",
    "        })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "normalized_fields: {'company_name': 'Hotel zur Taube', 'legal_form': 'Personengesellschaft', 'founding_date': '01.01.2010', 'business_address': 'Taubenstraße6, 89264', 'commercial_register': '3423431242', 'vat_id': '987654', 'property_type': 'Hotel zur Taube', 'property_name': 'Hotel zor Taube', 'property_address': 'Taubenstraße 6, 89264', 'purchase_price': '300.000', 'requested_amount': '220.000', 'purpose': 'Renovierung', 'equity_share': '60.0', 'construction_year': '2006', 'total_area': '250gm', 'loan_amount': '220.000', 'term': '50 Monate', 'monthly_payment': '5.000', 'interest_rate': 'fest'}\n",
      "extrahierte_daten_data: [{'Feldname': 'company_name', 'Wert': 'Hotel zur Taube', 'Position im Dokument': '[{\"x\": 3.6531, \"y\": 1.7283}, {\"x\": 4.8421, \"y\": 1.7283}, {\"x\": 4.8421, \"y\": 1.9049}, {\"x\": 3.6531, \"y\": 1.9049}]', 'Konfidenzscore': 0.98, 'FK_Dokument': '81e1a236-7ca1-452b-8ef6-4ade61a71bba'}, {'Feldname': 'legal_form', 'Wert': 'Personengesellschaft', 'Position im Dokument': '[{\"x\": 3.5767, \"y\": 1.9145}, {\"x\": 5.0236, \"y\": 1.9145}, {\"x\": 5.0236, \"y\": 2.0911}, {\"x\": 3.5767, \"y\": 2.0959}]', 'Konfidenzscore': 0.94, 'FK_Dokument': '81e1a236-7ca1-452b-8ef6-4ade61a71bba'}, {'Feldname': 'founding_date', 'Wert': '01.01.2010', 'Position im Dokument': '[{\"x\": 3.591, \"y\": 2.1198}, {\"x\": 4.3694, \"y\": 2.1198}, {\"x\": 4.3646, \"y\": 2.2391}, {\"x\": 3.591, \"y\": 2.2391}]', 'Konfidenzscore': 0.94, 'FK_Dokument': '81e1a236-7ca1-452b-8ef6-4ade61a71bba'}, {'Feldname': 'business_address', 'Wert': 'Taubenstraße6, 89264', 'Position im Dokument': '[{\"x\": 3.548, \"y\": 2.2869}, {\"x\": 5.2289, \"y\": 2.2821}, {\"x\": 5.2289, \"y\": 2.4349}, {\"x\": 3.548, \"y\": 2.4397}]', 'Konfidenzscore': 0.83, 'FK_Dokument': '81e1a236-7ca1-452b-8ef6-4ade61a71bba'}, {'Feldname': 'commercial_register', 'Wert': '3423431242', 'Position im Dokument': '[{\"x\": 3.5576, \"y\": 2.4922}, {\"x\": 4.5843, \"y\": 2.4922}, {\"x\": 4.5843, \"y\": 2.6259}, {\"x\": 3.5576, \"y\": 2.6259}]', 'Konfidenzscore': 0.99, 'FK_Dokument': '81e1a236-7ca1-452b-8ef6-4ade61a71bba'}, {'Feldname': 'vat_id', 'Wert': '987654', 'Position im Dokument': '[{\"x\": 3.548, \"y\": 2.6545}, {\"x\": 4.2261, \"y\": 2.6545}, {\"x\": 4.2261, \"y\": 2.8216}, {\"x\": 3.548, \"y\": 2.8216}]', 'Konfidenzscore': 0.98, 'FK_Dokument': '81e1a236-7ca1-452b-8ef6-4ade61a71bba'}, {'Feldname': 'property_type', 'Wert': 'Hotel zur Taube', 'Position im Dokument': '[{\"x\": 3.6531, \"y\": 1.7283}, {\"x\": 4.8421, \"y\": 1.7283}, {\"x\": 4.8421, \"y\": 1.9049}, {\"x\": 3.6531, \"y\": 1.9049}]', 'Konfidenzscore': 0.98, 'FK_Dokument': '81e1a236-7ca1-452b-8ef6-4ade61a71bba'}, {'Feldname': 'property_name', 'Wert': 'Hotel zor Taube', 'Position im Dokument': '[{\"x\": 3.5958, \"y\": 3.4041}, {\"x\": 4.6177, \"y\": 3.3945}, {\"x\": 4.6177, \"y\": 3.5473}, {\"x\": 3.6006, \"y\": 3.5569}]', 'Konfidenzscore': 0.92, 'FK_Dokument': '81e1a236-7ca1-452b-8ef6-4ade61a71bba'}, {'Feldname': 'property_address', 'Wert': 'Taubenstraße 6, 89264', 'Position im Dokument': '[{\"x\": 3.5385, \"y\": 3.5807}, {\"x\": 5.2433, \"y\": 3.576}, {\"x\": 5.2433, \"y\": 3.7383}, {\"x\": 3.5385, \"y\": 3.7383}]', 'Konfidenzscore': 0.98, 'FK_Dokument': '81e1a236-7ca1-452b-8ef6-4ade61a71bba'}, {'Feldname': 'purchase_price', 'Wert': '300.000', 'Position im Dokument': '[{\"x\": 3.6053, \"y\": 3.7765}, {\"x\": 4.2691, \"y\": 3.7717}, {\"x\": 4.2691, \"y\": 3.9293}, {\"x\": 3.6053, \"y\": 3.934}]', 'Konfidenzscore': 0.99, 'FK_Dokument': '81e1a236-7ca1-452b-8ef6-4ade61a71bba'}, {'Feldname': 'requested_amount', 'Wert': '220.000', 'Position im Dokument': '[{\"x\": 3.6053, \"y\": 3.9722}, {\"x\": 4.2643, \"y\": 3.9722}, {\"x\": 4.2643, \"y\": 4.0916}, {\"x\": 3.6053, \"y\": 4.0916}]', 'Konfidenzscore': 0.92, 'FK_Dokument': '81e1a236-7ca1-452b-8ef6-4ade61a71bba'}, {'Feldname': 'purpose', 'Wert': 'Renovierung', 'Position im Dokument': '[{\"x\": 3.5815, \"y\": 4.1441}, {\"x\": 4.4935, \"y\": 4.1632}, {\"x\": 4.4935, \"y\": 4.3112}, {\"x\": 3.5815, \"y\": 4.2873}]', 'Konfidenzscore': 0.77, 'FK_Dokument': '81e1a236-7ca1-452b-8ef6-4ade61a71bba'}, {'Feldname': 'equity_share', 'Wert': '60.0', 'Position im Dokument': '[{\"x\": 3.634, \"y\": 4.3303}, {\"x\": 3.9921, \"y\": 4.3255}, {\"x\": 3.9874, \"y\": 4.4497}, {\"x\": 3.634, \"y\": 4.4544}]', 'Konfidenzscore': 0.99, 'FK_Dokument': '81e1a236-7ca1-452b-8ef6-4ade61a71bba'}, {'Feldname': 'construction_year', 'Wert': '2006', 'Position im Dokument': '[{\"x\": 3.6149, \"y\": 4.5165}, {\"x\": 4.0447, \"y\": 4.5117}, {\"x\": 4.0447, \"y\": 4.6406}, {\"x\": 3.6197, \"y\": 4.6454}]', 'Konfidenzscore': 0.93, 'FK_Dokument': '81e1a236-7ca1-452b-8ef6-4ade61a71bba'}, {'Feldname': 'total_area', 'Wert': '250gm', 'Position im Dokument': '[{\"x\": 3.6531, \"y\": 4.7027}, {\"x\": 4.2404, \"y\": 4.7027}, {\"x\": 4.2404, \"y\": 4.8364}, {\"x\": 3.6531, \"y\": 4.8316}]', 'Konfidenzscore': 0.96, 'FK_Dokument': '81e1a236-7ca1-452b-8ef6-4ade61a71bba'}, {'Feldname': 'loan_amount', 'Wert': '220.000', 'Position im Dokument': '[{\"x\": 3.591, \"y\": 5.2565}, {\"x\": 4.2882, \"y\": 5.2565}, {\"x\": 4.2882, \"y\": 5.3902}, {\"x\": 3.591, \"y\": 5.3902}]', 'Konfidenzscore': 0.93, 'FK_Dokument': '81e1a236-7ca1-452b-8ef6-4ade61a71bba'}, {'Feldname': 'term', 'Wert': '50 Monate', 'Position im Dokument': '[{\"x\": 3.6006, \"y\": 5.4427}, {\"x\": 4.4267, \"y\": 5.4475}, {\"x\": 4.4219, \"y\": 5.5859}, {\"x\": 3.6006, \"y\": 5.5812}]', 'Konfidenzscore': 0.99, 'FK_Dokument': '81e1a236-7ca1-452b-8ef6-4ade61a71bba'}, {'Feldname': 'monthly_payment', 'Wert': '5.000', 'Position im Dokument': '[{\"x\": 3.5767, \"y\": 5.6385}, {\"x\": 3.9969, \"y\": 5.6337}, {\"x\": 3.9969, \"y\": 5.7626}, {\"x\": 3.5767, \"y\": 5.7626}]', 'Konfidenzscore': 0.98, 'FK_Dokument': '81e1a236-7ca1-452b-8ef6-4ade61a71bba'}, {'Feldname': 'interest_rate', 'Wert': 'fest', 'Position im Dokument': '[{\"x\": 3.5767, \"y\": 5.8056}, {\"x\": 3.8871, \"y\": 5.796}, {\"x\": 3.8871, \"y\": 5.944}, {\"x\": 3.5767, \"y\": 5.9392}]', 'Konfidenzscore': 0.99, 'FK_Dokument': '81e1a236-7ca1-452b-8ef6-4ade61a71bba'}]\n",
      "Results written to ocr_results.xlsx\n"
     ]
    }
   ],
   "source": [
    "print(\"normalized_fields:\", normalized_fields)\n",
    "print(\"extrahierte_daten_data:\", extrahierte_daten_data)\n",
    "\n",
    "with pd.ExcelWriter(f\"notebooks/docs/{customer_name}/{document_id}_ocr_results.xlsx\") as writer:\n",
    "    pd.DataFrame(extrahierte_daten_data).to_excel(writer, sheet_name=\"Extrahierte Daten\", index=False)\n",
    "\n",
    "print(\"Results written to ocr_results.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ollama container stopped and removed successfully\n"
     ]
    }
   ],
   "source": [
    "# Stop and remove the Ollama container\n",
    "try:\n",
    "    ollama_container.stop()\n",
    "    print(\"Ollama container stopped and removed successfully\")\n",
    "except Exception as e:\n",
    "    print(f\"Error stopping/removing container: {e}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
